{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOkzeG4BeHBh1xsM0yjdS98",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stuart-lane/MachineLearning/blob/main/LogitNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHs_5qnSr5Y8",
        "outputId": "fb3069eb-5d75-41df-dcbe-64066b1be168"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletedProcess(args=['pip', 'install', 'torch-cpu'], returncode=1)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "# Set environment variables\n",
        "os.environ[\"CUDA\"] = \"cpu\" # Set CUDA to CPU (no GPU support)\n",
        "os.environ[\"TORCH INSTALL\"] = \"1\"\n",
        "\n",
        "# Install the torch package\n",
        "subprocess.run([\"pip\", \"install\", \"torch\"])\n",
        "\n",
        "subprocess.run([\"pip\", \"install\", \"torch-cpu\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ISLP"
      ],
      "metadata": {
        "id": "DQBjx16qsAeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ISLP import load_data\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn"
      ],
      "metadata": {
        "id": "z8URDWibsybs"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "default = load_data(\"Default\")"
      ],
      "metadata": {
        "id": "MwdnJxl_tB0O"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "default[\"default1\"] = (default[\"default\"] == 1).astype(int)"
      ],
      "metadata": {
        "id": "wVq0WSx9tHmE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "default.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NAAI3UgetE6w",
        "outputId": "62fcac6c-2926-4e65-b878-ec7738868315"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  default student      balance        income  default1\n",
              "0      No      No   729.526495  44361.625074         0\n",
              "1      No     Yes   817.180407  12106.134700         0\n",
              "2      No      No  1073.549164  31767.138947         0\n",
              "3      No      No   529.250605  35704.493935         0\n",
              "4      No      No   785.655883  38463.495879         0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-06d2caef-9e26-4563-a190-921cad78a675\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>default</th>\n",
              "      <th>student</th>\n",
              "      <th>balance</th>\n",
              "      <th>income</th>\n",
              "      <th>default1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>729.526495</td>\n",
              "      <td>44361.625074</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>817.180407</td>\n",
              "      <td>12106.134700</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>1073.549164</td>\n",
              "      <td>31767.138947</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>529.250605</td>\n",
              "      <td>35704.493935</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>785.655883</td>\n",
              "      <td>38463.495879</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06d2caef-9e26-4563-a190-921cad78a675')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-06d2caef-9e26-4563-a190-921cad78a675 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-06d2caef-9e26-4563-a190-921cad78a675');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9de679d3-9243-4cf6-ac74-17cf251aa2a4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9de679d3-9243-4cf6-ac74-17cf251aa2a4')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9de679d3-9243-4cf6-ac74-17cf251aa2a4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x = default[['balance', 'income']].values # Include a column of ones for the intercept\n",
        "y = default['default1'].values\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.5, random_state = 123)"
      ],
      "metadata": {
        "id": "AVAyUbdTtFxG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.optim import LBFGS"
      ],
      "metadata": {
        "id": "rmAXYTYTwoU6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have 'train' DataFrame with 'balance' and 'income' columns\n",
        "x = torch.tensor(x, dtype = torch.float64)\n",
        "x.requires_grad = True\n",
        "\n",
        "y = torch.tensor(y, dtype = torch.float64)\n",
        "y.requires_grad = True\n",
        "\n",
        "beta = torch.randn(3, 1, dtype = torch.float64)\n",
        "beta.requires_grad = True\n",
        "\n",
        "# Check if CUDA (GPU) is available\n",
        "if torch.cuda.is_available():\n",
        "    dev = \"cuda\"\n",
        "else:\n",
        "    dev = \"cpu\"\n",
        "\n",
        "print(f\"Running on: {dev}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpZORKyawI02",
        "outputId": "b5e86558-80d4-4f43-c44c-3d49e766ccc7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "3vzjhRQ0wkOA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LogitModel(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(LogitModel, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "input_dim = 2\n",
        "output_dim = 1\n",
        "net = LogitModel(input_dim, output_dim)"
      ],
      "metadata": {
        "id": "5FncbZE8yPq6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(net.parameters())"
      ],
      "metadata": {
        "id": "ZZv2eC3Xynlb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training settings\n",
        "\n",
        "epochs = 50000\n",
        "loss_function = nn.BCELoss()\n",
        "\n",
        "x = x.to(next(net.parameters()).dtype)\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    optimizer.zero_grad()\n",
        "    output = net(x)\n",
        "    loss = loss_function(output.squeeze(), y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if (epoch % (epochs / 50) == 0):\n",
        "      print(f\"{epoch}: {loss.item()}\")\n",
        "\n",
        "print(\"Learned parameters:\")\n",
        "print(f\"{net.linear.weight}\")\n",
        "print(f\"{net.linear.bias}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "3ccFWkT9yzJ8",
        "outputId": "1e20b94c-1f84-4280-d179-4657deb56d12"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-50817cadb9d5>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3096\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3098\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found dtype Double but expected Float"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x = default[['balance', 'income']].values # Include a column of ones for the intercept\n",
        "y = default['default1'].values\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.5, random_state = 123)\n",
        "\n",
        "# Assuming you have 'train' DataFrame with 'balance' and 'income' columns\n",
        "x = torch.tensor(x_train, dtype = torch.float64)\n",
        "x.requires_grad = True\n",
        "\n",
        "y = torch.tensor(y_train, dtype = torch.float64)\n",
        "y.requires_grad = True\n",
        "\n",
        "beta = torch.randn(3, 1, dtype = torch.float64)\n",
        "beta.requires_grad = True\n",
        "\n",
        "class LogitModel(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(LogitModel, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "input_dim = 2\n",
        "output_dim = 1\n",
        "net = LogitModel(input_dim, output_dim)\n",
        "\n",
        "x = x.to(next(net.parameters()).dtype)\n",
        "\n",
        "optimizer = torch.optim.Adam(net.parameters())\n",
        "\n",
        "# Training settings\n",
        "\n",
        "epochs = 50000\n",
        "loss_function = nn.BCELoss()\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    optimizer.zero_grad()\n",
        "    output = net(x)\n",
        "    loss = loss_function(output.squeeze(), y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if (epoch % (epochs / 50) == 0):\n",
        "      print(f\"{epoch}: {loss.item()}\")\n",
        "\n",
        "print(\"Learned parameters:\")\n",
        "print(f\"{net.linear.weight}\")\n",
        "print(f\"{net.linear.bias}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "VwDB12mr1B6Z",
        "outputId": "c5debc2d-d04a-4908-d969-032a0e0b94db"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-3bba6d34d94f>\u001b[0m in \u001b[0;36m<cell line: 41>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3096\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3098\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found dtype Double but expected Float"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define single-layer neural network (logistic regression)\n",
        "class LogitModel(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(LogitModel, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "# Initialize model and optimizer\n",
        "input_dim = x.shape[1]\n",
        "output_dim = 1\n",
        "\n",
        "net = LogitModel(input_dim, output_dim)\n",
        "optimizer = optim.Adam(net.parameters())\n",
        "\n",
        "# Training settings\n",
        "epochs = 50000\n",
        "loss_function = nn.BCELoss().float()\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(1, epochs + 1):\n",
        "    optimizer.zero_grad()\n",
        "    x = x.float()\n",
        "    output = net(x)\n",
        "    loss = loss_function(output.squeeze(), y.squeeze())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % (epochs // 50) == 0:\n",
        "        print(f\"{epoch}: {loss.item()}\")\n",
        "\n",
        "# View the learned parameters\n",
        "print(\"Learned parameters:\")\n",
        "print(net.linear.weight)\n",
        "print(net.linear.bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQzzG2ZC1N13",
        "outputId": "18a3b491-e4c3-4759-cc21-3c9bafa60fa2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000: 0.0\n",
            "2000: 0.0\n",
            "3000: 0.0\n",
            "4000: 0.0\n",
            "5000: 0.0\n",
            "6000: 0.0\n",
            "7000: 0.0\n",
            "8000: 0.0\n",
            "9000: 0.0\n",
            "10000: 0.0\n",
            "11000: 0.0\n",
            "12000: 0.0\n",
            "13000: 0.0\n",
            "14000: 0.0\n",
            "15000: 0.0\n",
            "16000: 0.0\n",
            "17000: 0.0\n",
            "18000: 0.0\n",
            "19000: 0.0\n",
            "20000: 0.0\n",
            "21000: 0.0\n",
            "22000: 0.0\n",
            "23000: 0.0\n",
            "24000: 0.0\n",
            "25000: 0.0\n",
            "26000: 0.0\n",
            "27000: 0.0\n",
            "28000: 0.0\n",
            "29000: 0.0\n",
            "30000: 0.0\n",
            "31000: 0.0\n",
            "32000: 0.0\n",
            "33000: 0.0\n",
            "34000: 0.0\n",
            "35000: 0.0\n",
            "36000: 0.0\n",
            "37000: 0.0\n",
            "38000: 0.0\n",
            "39000: 0.0\n",
            "40000: 0.0\n",
            "41000: 0.0\n",
            "42000: 0.0\n",
            "43000: 0.0\n",
            "44000: 0.0\n",
            "45000: 0.0\n",
            "46000: 0.0\n",
            "47000: 0.0\n",
            "48000: 0.0\n",
            "49000: 0.0\n",
            "50000: 0.0\n",
            "Learned parameters:\n",
            "Parameter containing:\n",
            "tensor([[-0.1358, -0.4572]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.6065], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "x = default[['balance', 'income']].values # Include a column of ones for the intercept\n",
        "y = default['default1'].values\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.5, random_state = 123)\n",
        "\n",
        "# Define a simple logistic regression model\n",
        "class LogitModel(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(LogitModel, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, 1)  # Single output unit\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.to(self.linear.weight.dtype)  # Cast input to the same data type as the model's parameters\n",
        "        x = self.linear(x)\n",
        "        x = torch.sigmoid(x)  # Apply sigmoid activation for binary classification\n",
        "        return x\n",
        "\n",
        "# Assuming you have 'train' DataFrame with 'balance' and 'income' columns\n",
        "x = torch.tensor(x_train, dtype = torch.float64)\n",
        "x.requires_grad = True\n",
        "\n",
        "y = torch.tensor(y_train, dtype = torch.float64)\n",
        "y.requires_grad = True\n",
        "y = y.reshape(-1, 1)\n",
        "\n",
        "beta = torch.randn(x.shape[1], 1, dtype = torch.float64)\n",
        "beta.requires_grad = True"
      ],
      "metadata": {
        "id": "sqIrSonL1tdQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26pSJhNI_B7g",
        "outputId": "08dfddc8-5843-4410-b736-b51a6c59c558"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5000, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "x = default[['balance', 'income']].values # Include a column of ones for the intercept\n",
        "y = default['default1'].values\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.5, random_state = 123)\n",
        "\n",
        "# Define a simple logistic regression model\n",
        "class LogitModel(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(LogitModel, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, 1)  # Single output unit\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.to(self.linear.weight.dtype)  # Cast input to the same data type as the model's parameters\n",
        "        x = self.linear(x)\n",
        "        x = torch.sigmoid(x)  # Apply sigmoid activation for binary classification\n",
        "        return x\n",
        "\n",
        "# Assuming you have 'train' DataFrame with 'balance' and 'income' columns\n",
        "x = torch.tensor(x_train, dtype = torch.float64)\n",
        "x.requires_grad = True\n",
        "\n",
        "y = torch.tensor(y_train, dtype = torch.float64)\n",
        "y.requires_grad = True\n",
        "y = y.reshape(-1, 1)\n",
        "\n",
        "beta = torch.randn(x.shape[1], 1, dtype = torch.float64)\n",
        "beta.requires_grad = True\n",
        "\n",
        "# Create a DataLoader for your dataset (not shown in this example)\n",
        "\n",
        "# Define model input dimension based on the number of features in your data\n",
        "input_dim = x.shape[1]\n",
        "\n",
        "# Create an instance of the LogitModel\n",
        "model = LogitModel(input_dim)\n",
        "\n",
        "# Define a binary cross-entropy loss function\n",
        "loss_function = nn.BCELoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Set the number of training epochs\n",
        "epochs = 50000\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    optimizer.zero_grad()  # Zero the gradients\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(x)\n",
        "\n",
        "    outputs = outputs.float()\n",
        "    y = y.float()\n",
        "\n",
        "    # Calculate the loss\n",
        "    loss = loss_function(outputs, y)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "\n",
        "    # Update the model's parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print training progress\n",
        "    if epoch % (epochs / 50) == 0:\n",
        "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "  # View the learned parameters\n",
        "print(\"Learned parameters:\")\n",
        "print(f\"{model.linear.weight}\")\n",
        "print(f\"{net.linear.bias}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0G2Fp2Xj-G8o",
        "outputId": "f978898a-dcda-47ba-c136-ce8529368f2f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50000], Loss: 0.0000\n",
            "Epoch [1001/50000], Loss: 0.0000\n",
            "Epoch [2001/50000], Loss: 0.0000\n",
            "Epoch [3001/50000], Loss: 0.0000\n",
            "Epoch [4001/50000], Loss: 0.0000\n",
            "Epoch [5001/50000], Loss: 0.0000\n",
            "Epoch [6001/50000], Loss: 0.0000\n",
            "Epoch [7001/50000], Loss: 0.0000\n",
            "Epoch [8001/50000], Loss: 0.0000\n",
            "Epoch [9001/50000], Loss: 0.0000\n",
            "Epoch [10001/50000], Loss: 0.0000\n",
            "Epoch [11001/50000], Loss: 0.0000\n",
            "Epoch [12001/50000], Loss: 0.0000\n",
            "Epoch [13001/50000], Loss: 0.0000\n",
            "Epoch [14001/50000], Loss: 0.0000\n",
            "Epoch [15001/50000], Loss: 0.0000\n",
            "Epoch [16001/50000], Loss: 0.0000\n",
            "Epoch [17001/50000], Loss: 0.0000\n",
            "Epoch [18001/50000], Loss: 0.0000\n",
            "Epoch [19001/50000], Loss: 0.0000\n",
            "Epoch [20001/50000], Loss: 0.0000\n",
            "Epoch [21001/50000], Loss: 0.0000\n",
            "Epoch [22001/50000], Loss: 0.0000\n",
            "Epoch [23001/50000], Loss: 0.0000\n",
            "Epoch [24001/50000], Loss: 0.0000\n",
            "Epoch [25001/50000], Loss: 0.0000\n",
            "Epoch [26001/50000], Loss: 0.0000\n",
            "Epoch [27001/50000], Loss: 0.0000\n",
            "Epoch [28001/50000], Loss: 0.0000\n",
            "Epoch [29001/50000], Loss: 0.0000\n",
            "Epoch [30001/50000], Loss: 0.0000\n",
            "Epoch [31001/50000], Loss: 0.0000\n",
            "Epoch [32001/50000], Loss: 0.0000\n",
            "Epoch [33001/50000], Loss: 0.0000\n",
            "Epoch [34001/50000], Loss: 0.0000\n",
            "Epoch [35001/50000], Loss: 0.0000\n",
            "Epoch [36001/50000], Loss: 0.0000\n",
            "Epoch [37001/50000], Loss: 0.0000\n",
            "Epoch [38001/50000], Loss: 0.0000\n",
            "Epoch [39001/50000], Loss: 0.0000\n",
            "Epoch [40001/50000], Loss: 0.0000\n",
            "Epoch [41001/50000], Loss: 0.0000\n",
            "Epoch [42001/50000], Loss: 0.0000\n",
            "Epoch [43001/50000], Loss: 0.0000\n",
            "Epoch [44001/50000], Loss: 0.0000\n",
            "Epoch [45001/50000], Loss: 0.0000\n",
            "Epoch [46001/50000], Loss: 0.0000\n",
            "Epoch [47001/50000], Loss: 0.0000\n",
            "Epoch [48001/50000], Loss: 0.0000\n",
            "Epoch [49001/50000], Loss: 0.0000\n",
            "Learned parameters:\n",
            "Parameter containing:\n",
            "tensor([[ 0.2341, -0.4211]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0223], requires_grad=True)\n"
          ]
        }
      ]
    }
  ]
}